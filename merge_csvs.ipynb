{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59e580d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07695af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder containing CSV files\n",
    "folder_path = r'D:\\Shivam\\DS_jobs_analysis\\DS_Jobs-2024'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d76b4f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all CSV files in folder\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f91dbceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty DataFrame\n",
    "combined_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a30f7532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop each CSV file\n",
    "\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Keep only new columns that are not in combined_df\n",
    "    new_columns = [col for col in df.columns if col not in combined_df.columns]\n",
    "    \n",
    "    if new_columns:\n",
    "        combined_df = pd.concat([combined_df, df[new_columns]], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db3e4864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined csv with unique columns saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# save combined csv\n",
    "combined_df.to_csv('Combined_DS-Jobs_data.csv', index=False)\n",
    "\n",
    "print('Combined csv with unique columns saved successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8740f1ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_link</th>\n",
       "      <th>last_processed_time</th>\n",
       "      <th>last_status</th>\n",
       "      <th>got_summary</th>\n",
       "      <th>got_ner</th>\n",
       "      <th>is_being_worked</th>\n",
       "      <th>job_title</th>\n",
       "      <th>company</th>\n",
       "      <th>job_location</th>\n",
       "      <th>first_seen</th>\n",
       "      <th>search_city</th>\n",
       "      <th>search_country</th>\n",
       "      <th>search_position</th>\n",
       "      <th>job_level</th>\n",
       "      <th>job_type</th>\n",
       "      <th>job_skills</th>\n",
       "      <th>job_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/senior-mach...</td>\n",
       "      <td>2024-01-21 08:08:48.031964+00</td>\n",
       "      <td>Finished NER</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>Senior Machine Learning Engineer</td>\n",
       "      <td>Jobs for Humanity</td>\n",
       "      <td>New Haven, CT</td>\n",
       "      <td>14-01-2024</td>\n",
       "      <td>East Haven</td>\n",
       "      <td>United States</td>\n",
       "      <td>Agricultural-Research Engineer</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Machine Learning, Programming, Python, Scala, ...</td>\n",
       "      <td>Company Description\\nJobs for Humanity is part...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/principal-s...</td>\n",
       "      <td>2024-01-20 04:02:12.331406+00</td>\n",
       "      <td>Finished NER</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>Principal Software Engineer, ML Accelerators</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>14-01-2024</td>\n",
       "      <td>El Cerrito</td>\n",
       "      <td>United States</td>\n",
       "      <td>Set-Key Driver</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>C++, Python, PyTorch, TensorFlow, MXNet, CUDA,...</td>\n",
       "      <td>Who We Are\\nAurora (Nasdaq: AUR) is delivering...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/senior-etl-...</td>\n",
       "      <td>2024-01-21 08:08:31.941595+00</td>\n",
       "      <td>Finished NER</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>Senior ETL Data Warehouse Specialist</td>\n",
       "      <td>Adame Services LLC</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>14-01-2024</td>\n",
       "      <td>Middletown</td>\n",
       "      <td>United States</td>\n",
       "      <td>Technical Support Specialist</td>\n",
       "      <td>Associate</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>ETL, Data Integration, Data Transformation, Da...</td>\n",
       "      <td>Location: New York City, NY\\nPosition Summary\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/senior-data...</td>\n",
       "      <td>2024-01-20 15:30:55.796572+00</td>\n",
       "      <td>Finished NER</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>Senior Data Warehouse Developer / Architect</td>\n",
       "      <td>Morph Enterprise</td>\n",
       "      <td>Harrisburg, PA</td>\n",
       "      <td>12-01-2024</td>\n",
       "      <td>Lebanon</td>\n",
       "      <td>United States</td>\n",
       "      <td>Architect</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Data Lakes, Data Bricks, Azure Data Factory Pi...</td>\n",
       "      <td>Responsibilities:\\nCandidate must have signifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/lead-data-e...</td>\n",
       "      <td>2024-01-21 08:08:58.312124+00</td>\n",
       "      <td>Finished NER</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>Lead Data Engineer</td>\n",
       "      <td>Dice</td>\n",
       "      <td>Plano, TX</td>\n",
       "      <td>14-01-2024</td>\n",
       "      <td>McKinney</td>\n",
       "      <td>United States</td>\n",
       "      <td>Maintenance Data Analyst</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Java, Scala, Python, RDBMS, NoSQL, Redshift, S...</td>\n",
       "      <td>Dice is the leading career destination for tec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            job_link  \\\n",
       "0  https://www.linkedin.com/jobs/view/senior-mach...   \n",
       "1  https://www.linkedin.com/jobs/view/principal-s...   \n",
       "2  https://www.linkedin.com/jobs/view/senior-etl-...   \n",
       "3  https://www.linkedin.com/jobs/view/senior-data...   \n",
       "4  https://www.linkedin.com/jobs/view/lead-data-e...   \n",
       "\n",
       "             last_processed_time   last_status got_summary got_ner  \\\n",
       "0  2024-01-21 08:08:48.031964+00  Finished NER           t       t   \n",
       "1  2024-01-20 04:02:12.331406+00  Finished NER           t       t   \n",
       "2  2024-01-21 08:08:31.941595+00  Finished NER           t       t   \n",
       "3  2024-01-20 15:30:55.796572+00  Finished NER           t       t   \n",
       "4  2024-01-21 08:08:58.312124+00  Finished NER           t       t   \n",
       "\n",
       "  is_being_worked                                     job_title  \\\n",
       "0               f              Senior Machine Learning Engineer   \n",
       "1               f  Principal Software Engineer, ML Accelerators   \n",
       "2               f          Senior ETL Data Warehouse Specialist   \n",
       "3               f   Senior Data Warehouse Developer / Architect   \n",
       "4               f                            Lead Data Engineer   \n",
       "\n",
       "              company       job_location  first_seen search_city  \\\n",
       "0   Jobs for Humanity      New Haven, CT  14-01-2024  East Haven   \n",
       "1              Aurora  San Francisco, CA  14-01-2024  El Cerrito   \n",
       "2  Adame Services LLC       New York, NY  14-01-2024  Middletown   \n",
       "3    Morph Enterprise     Harrisburg, PA  12-01-2024     Lebanon   \n",
       "4                Dice          Plano, TX  14-01-2024    McKinney   \n",
       "\n",
       "  search_country                 search_position   job_level job_type  \\\n",
       "0  United States  Agricultural-Research Engineer  Mid senior   Onsite   \n",
       "1  United States                  Set-Key Driver  Mid senior   Onsite   \n",
       "2  United States    Technical Support Specialist   Associate   Onsite   \n",
       "3  United States                       Architect  Mid senior   Onsite   \n",
       "4  United States        Maintenance Data Analyst  Mid senior   Onsite   \n",
       "\n",
       "                                          job_skills  \\\n",
       "0  Machine Learning, Programming, Python, Scala, ...   \n",
       "1  C++, Python, PyTorch, TensorFlow, MXNet, CUDA,...   \n",
       "2  ETL, Data Integration, Data Transformation, Da...   \n",
       "3  Data Lakes, Data Bricks, Azure Data Factory Pi...   \n",
       "4  Java, Scala, Python, RDBMS, NoSQL, Redshift, S...   \n",
       "\n",
       "                                         job_summary  \n",
       "0  Company Description\\nJobs for Humanity is part...  \n",
       "1  Who We Are\\nAurora (Nasdaq: AUR) is delivering...  \n",
       "2  Location: New York City, NY\\nPosition Summary\\...  \n",
       "3  Responsibilities:\\nCandidate must have signifi...  \n",
       "4  Dice is the leading career destination for tec...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load file\n",
    "df= pd.read_csv('Combined_DS-Jobs_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d1b0b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12217, 17)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ca4872e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12217 entries, 0 to 12216\n",
      "Data columns (total 17 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   job_link             12217 non-null  object\n",
      " 1   last_processed_time  12217 non-null  object\n",
      " 2   last_status          12217 non-null  object\n",
      " 3   got_summary          12217 non-null  object\n",
      " 4   got_ner              12217 non-null  object\n",
      " 5   is_being_worked      12217 non-null  object\n",
      " 6   job_title            12217 non-null  object\n",
      " 7   company              12217 non-null  object\n",
      " 8   job_location         12216 non-null  object\n",
      " 9   first_seen           12217 non-null  object\n",
      " 10  search_city          12217 non-null  object\n",
      " 11  search_country       12217 non-null  object\n",
      " 12  search_position      12217 non-null  object\n",
      " 13  job_level            12217 non-null  object\n",
      " 14  job_type             12217 non-null  object\n",
      " 15  job_skills           12212 non-null  object\n",
      " 16  job_summary          12217 non-null  object\n",
      "dtypes: object(17)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e12b9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cff51b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
